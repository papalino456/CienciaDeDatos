# Mechatronics Sentence-Embedding Pipeline Configuration

scrape:
  max_pages_per_host: 200
  crawl_depth: 2
  request_rate_per_host: 1.0  # seconds between requests
  timeout: 30
  max_retries: 3
  user_agent: "Mozilla/5.0 (compatible; MechEmbedBot/1.0; Research)"
  
  # Wikipedia categories to scrape
  wikipedia_categories:
    - "Mechatronics"
    - "Control_engineering"
    - "Robotics"
    - "Sensors"
    - "Actuators"
    - "Programmable_logic_controller"
    - "Industrial_automation"
    - "Embedded_systems"
    - "Kinematics"
    - "Robot_kinematics"
    
  # arXiv categories (API-based, abstracts only)
  arxiv_categories:
    - "cs.RO"  # Robotics
    - "eess.SY"  # Systems and Control
    - "cs.AI"  # AI (filtered for robotics)
  arxiv_max_results: 500
  
clean:
  min_sentence_length: 10  # characters
  max_sentence_length: 512  # characters
  min_word_count: 3
  max_word_count: 100
  dedup_threshold: 0.85  # Jaccard similarity for near-duplicates
  english_confidence: 0.9
  
topics:
  # Topic buckets with keywords
  buckets:
    control:
      keywords: ["control", "controller", "pid", "feedback", "servo", "regulation", "stability"]
    robotics:
      keywords: ["robot", "robotic", "manipulator", "end-effector", "trajectory", "path planning"]
    sensors:
      keywords: ["sensor", "transducer", "encoder", "lidar", "camera", "ultrasonic", "imu"]
    actuators:
      keywords: ["actuator", "motor", "stepper", "servo motor", "hydraulic", "pneumatic", "drive"]
    plc:
      keywords: ["plc", "programmable logic", "ladder logic", "scada", "hmi", "industrial control"]
    embedded:
      keywords: ["embedded", "microcontroller", "firmware", "real-time", "rtos", "arduino", "raspberry pi"]
    kinematics:
      keywords: ["kinematic", "forward kinematics", "inverse kinematics", "jacobian", "degrees of freedom"]
    dynamics:
      keywords: ["dynamic", "force", "torque", "inertia", "momentum", "equations of motion"]
  
  target_samples_per_bucket: 2000
  min_samples_per_bucket: 500

tokenizer:
  algorithm: "wordpiece"  # or "bpe"
  vocab_size: 16000
  min_frequency: 2
  lowercase: true
  strip_accents: true
  special_tokens: ["[PAD]", "[UNK]", "[CLS]", "[SEP]", "[MASK]"]

model:
  hidden_size: 256
  num_hidden_layers: 4
  num_attention_heads: 4
  intermediate_size: 1024
  max_position_embeddings: 512
  hidden_dropout_prob: 0.1
  attention_probs_dropout_prob: 0.1
  layer_norm_eps: 1.0e-12
  initializer_range: 0.02

train:
  mlm:
    batch_size: 32
    gradient_accumulation_steps: 2
    learning_rate: 5.0e-4
    weight_decay: 0.01
    warmup_steps: 500
    max_steps: 10000
    epochs: 5
    mlm_probability: 0.15
    fp16: true
    logging_steps: 100
    save_steps: 1000
    eval_steps: 500
    
  tsdae:
    batch_size: 16
    gradient_accumulation_steps: 4
    learning_rate: 3.0e-5
    weight_decay: 0.01
    warmup_ratio: 0.1
    epochs: 3
    deletion_prob: 0.6  # probability of deleting a token
    fp16: true
    logging_steps: 50
    save_steps: 500
    max_seq_length: 256
    
  simcse:
    batch_size: 64
    gradient_accumulation_steps: 1
    learning_rate: 3.0e-5
    weight_decay: 0.01
    warmup_ratio: 0.05
    epochs: 3
    temperature: 0.05
    pooler_type: "cls_before_pooler"  # or "avg"
    fp16: true
    logging_steps: 50
    save_steps: 500
    max_seq_length: 256
    hard_negative_weight: 0  # no hard negatives in unsupervised
    use_topic_labels: true  # enable supervised contrastive loss using topics

eval:
  test_samples_per_bucket: 125  # 125 * 8 = 1000 total
  pca_components: 3
  random_seed: 42
  umap:
    n_components: 3
    n_neighbors: 5  # Lower values (5-15) emphasize local structure and exaggerate separation
    min_dist: 0.005  # Lower values (0.0-0.1) create tighter clusters, better separation
    metric: "cosine"  # Good for embeddings

paths:
  raw_data: "data/raw"
  interim_data: "data/interim"
  clean_data: "data/clean"
  balanced_data: "data/balanced"
  tokenizer_dir: "data/tokenizer"
  splits_dir: "data/splits"
  test_dir: "data/test"
  models_dir: "artifacts/models"
  logs_dir: "artifacts/logs"
  eval_dir: "artifacts/eval"

